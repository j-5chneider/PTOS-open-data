[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "PTOS-open-data",
    "section": "",
    "text": "Welcome\nThis is a workshop on open and FAIR data.\n\nCC-BY aukeherrema.nl\n\n\n\n\nIf you like the workshop…\n\nand want to keep it forever, make it yoursgive it a star in GitHub\n\n\nFor that…\n\nFork the github repo this Quarto book is based on\nGo to settings of your new repo and go to the “pages” section. Then set the “Branch” option to gh-pages (leave the dropdown to the right of this at /root)\nWait a minute to let the website get deployed. You can check on the status in the “Actions” tab of your repo.\nBack on the main repo site, click on “About” (top right). In the URL of the website, change “j-5chneider” to your username “[your github username].github.io/PTOS-open-data/” (you might need to activate GitHub Pages for that, by creating a GitHub Pages repo)\nopen your new webpage by clicking on that link in the “About” section\n\n\n\n\n\nSo you get noticed if I update something on the github repo.\nAnd I get that sweet sweet dopamine. Hmm dopamine."
  },
  {
    "objectID": "transparency.html",
    "href": "transparency.html",
    "title": "Transparency",
    "section": "",
    "text": "Affiliation\n\n\n\n\nDIPF | Leibniz Institute for Research and Information in Education\nProject in the Cooperation Center ShaReD - Sharing and Reusing Data\nSee personal webpage\n\n\n\n\n\n\nCooperation\n\n\n\n\n\n\nWorking closely together, but not at the research data center at DIPF"
  },
  {
    "objectID": "reasons.html",
    "href": "reasons.html",
    "title": "1  Exercise: Your reasons",
    "section": "",
    "text": "What are your reasons?\nNow that you are here, there seem to be some drivers for you to share data. What are these?\n\nGo to this whiteboard\nTake one or more of the blue rectangles from the right\nWrite your reason in the rectangle. One reason per shape.\n\n\n\n\n\nQuestions to be answered at the end?\nPlease put them here!"
  },
  {
    "objectID": "reasons_external1.html#research-funders",
    "href": "reasons_external1.html#research-funders",
    "title": "2  External Incentives I",
    "section": "2.1 Research funders",
    "text": "2.1 Research funders\n\n\n\n\n\n\nDFG\n\n\n\nDFG Guidelines on the Handling of Research Data\n\n“Assuming that the publication of research data […] does not conflict with the rights of third parties (in particular data protection or copyright), research data should be made available as soon as possible […] that allows it to be usefully reused by third parties” (DFG, 2015, p. 1)\n\nGuidelines for Safeguarding Good Research Practice. Code of Conduct\n\n“Where possible and reasonable, this includes making the research data […] available” (DFG, 2019, p. 19)\n\n\n\n\n\n\n\n\n\n\n\nBMBF\n\n\n\nTypical section in calls for proposals\n\n“Zuwendungsempfänger sollen, wann immer möglich, die im Rahmen des Projekts gewonnenen Daten […] in nachnutzbarer Form einer geeigneten Einrichtung […] zur Verfügung stellen, um […] Replikationen und gegebenenfalls Sekundärauswertungen […] zu ermöglichen. Repositorien sollten aktuelle Standards für Datenveröffentlichungen (FAIR Data-Prinzipien) erfüllen”\n\nz.B. in\n\n\nAusschreibung “Wissenschafts- und Hochschulforschung (WiHo)” 10.11.2023\nBMBF, 2023\n\nAusschreibung zu “klinischen Studien mit hoher Relevanz für die Patientenversorgung” 09.11.2023 BMBF, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nERC\n\n\n\nOpen Research Data and Data Management Plans Information for ERC grantees\n\n“Grantees are required to deposit their research data in a repository and provide open access at least to those data” (ERC, 2022, p. 4)\n\n\n\n\n\n\n\nQuestions to be answered at the end?\nPlease put them here!\n\n\nDFG. (2015). DFG Guidelines on the Handling of Research Data.\n\n\nDFG. (2019). Guidelines for Safeguarding Good Research Practice. Code of Conduct.\n\n\nERC. (2022). Open Research Data and Data Management Plans. Information for ERC grantees."
  },
  {
    "objectID": "reasons_external2.html#policies-scientific-societies",
    "href": "reasons_external2.html#policies-scientific-societies",
    "title": "3  External Incentives II",
    "section": "3.1 Policies scientific societies",
    "text": "3.1 Policies scientific societies\nExamples of societies that have established a policy on open and FAIR data.\n    \n(DGfE et al., 2020; DGS, 2019; Gollwitzer et al., 2021)\n\n\n\n “Homework”: Look up the scientific society most relevant to you and check if they have a policy/recommendation/guideline on open science or sharing data. What does it say on openness, FAIRness and limitations?"
  },
  {
    "objectID": "reasons_external2.html#journal-policies",
    "href": "reasons_external2.html#journal-policies",
    "title": "3  External Incentives II",
    "section": "3.2 Journal policies",
    "text": "3.2 Journal policies\nSome journals encourage, some journals mandate a data availability statement in the manuscript.\n\nE.g.,\n\nPsychological Bulletin: Data transparency Level 2\nMeta Psychology: Data transparency Level 3\nPsychological Science: Data transparency Level 1\n\nSee the TOP Factor website to search for the data transparency rating of your favorite journal.\n\n\n\n Evidence that “Data available upon reasonable request” often does not keep its promise. Only 6.8% of data sets were acutally provided in an investigation (Gabelica et al., 2022)\n\n\n\n\n\nQuestions to be answered at the end?\nPlease put them here!\n\n\nDGfE, GEBF, & GFD. (2020). Gemeinsame Stellungnahme der Deutschen Gesellschaft für Erziehungswissenschaft (DGfE), der Gesellschaft für Empirische Bildungsforschung (GEBF) und der Gesellschaft für Fachdidaktik (GFD) zur Archivierung, Bereitstellung und Nachnutzung von Forschungsdaten in den Erziehungs- und Bildungswissenschaften und Fachdidaktiken.\n\n\nDGS. (2019). Stellungnahme: Bereitstellung und Nachnutzung von Forschungsdaten in der Soziologie.\n\n\nGabelica, M., Bojčić, R., & Puljak, L. (2022). Many researchers were not compliant with their published data sharing statement: A mixed-methods study. Journal of Clinical Epidemiology, 150, 33–41. https://doi.org/10.1016/j.jclinepi.2022.05.019\n\n\nGollwitzer, M., Abele-Brehm, A., Fiebach, C. J., Ramthun, R., Scheel, A., Schönbrodt, F., & Steinberg, U. (2021). Management und Bereitstellung von Forschungsdaten in der Psychologie: Überarbeitung der DGPs-Empfehlungen: DGPs-Kommission ,,Open Science“ (beschlossen durch den Vorstand der DGPs am 26. 06. 2020). Psychologische Rundschau, 72(2), 132–146. https://doi.org/10.1026/0033-3042/a000514"
  },
  {
    "objectID": "reasons_research1.html#no-data-not-reproducible",
    "href": "reasons_research1.html#no-data-not-reproducible",
    "title": "4  Research I",
    "section": "4.1 No data = not reproducible",
    "text": "4.1 No data = not reproducible\nComputational reproducibility :=\n\n“a second investigator (including the original researcher in the future) can recreate the final reported results of the project, including key quantitative findings, tables, and figures, given only a set of files and written instructions” (Kitzes et al., 2018, p. xxii)\n\n Same data + same analysis = same results\n\n\nWhy reproducibility?\nAllows independent researchers to assess the analytic choices, assumptions, and implementations that led to a set of scientific claims.\n Check for validity and generalizability (Clyburne-Sherin et al., 2019; Obels et al., 2020)"
  },
  {
    "objectID": "reasons_research1.html#no-fair-data-reproducibility-tedious",
    "href": "reasons_research1.html#no-fair-data-reproducibility-tedious",
    "title": "4  Research I",
    "section": "4.2 No FAIR data = reproducibility tedious",
    "text": "4.2 No FAIR data = reproducibility tedious\nBut computational reproducibility isn’t as easy as it sounds (Artner et al., 2021)\n\nDesignResultsConclusions\n\n\n\nchecked 232 primary statistical claims\nfrom 3 journals\nafter data was provided and accessible (33%, 25%, 26%)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVagueness Makes Assessing Reproducibility a Nightmare\n\n\nmost successful reproductions are predominantly the result of tedious and time-consuming work\n\n\ninformation about the provided raw data was often difficult to understand, and information about the relevant variables, data manipulations, and the used statistical model was often vague or inaccurate\n\n(Artner et al., 2021, p. 12)"
  },
  {
    "objectID": "reasons_research1.html#no-data-barrier-to-replication",
    "href": "reasons_research1.html#no-data-barrier-to-replication",
    "title": "4  Research I",
    "section": "4.3 No data = barrier to replication",
    "text": "4.3 No data = barrier to replication\n\nEvidence e.g. from replication attempts in cancer biology (Errington et al., 2021)\nDue to various barriers, 50 of the 193 replication experiments could be conducted at all\nMissing data = major barrier to compute parameters to replicate\n\n data were open for 4 of 193 experiments\n\n\nQuestions to be answered at the end?\nPlease put them here!\n\n\n\n\n\n\nArtner, R., Verliefde, T., Steegen, S., Gomes, S., Traets, F., Tuerlinckx, F., & Vanpaemel, W. (2021). The reproducibility of statistical results in psychological research: An investigation using unpublished raw data. Psychological Methods, 26(5), 527–546. https://doi.org/10.1037/met0000365\n\n\nClyburne-Sherin, A., Fei, X., & Green, S. A. (2019). Computational Reproducibility via Containers in Psychology. Meta-Psychology, 3. https://doi.org/10.15626/MP.2018.892\n\n\nErrington, T. M., Denis, A., Perfito, N., Iorns, E., & Nosek, B. A. (2021). Challenges for assessing replicability in preclinical cancer biology. eLife, 10, e67995. https://doi.org/10.7554/eLife.67995\n\n\nKitzes, J., Turek, D., & Deniz, F. (Eds.). (2018). The practice of reproducible research: Case studies and lessons from the data-intensive sciences. University of California Press.\n\n\nObels, P., Lakens, D., Coles, N. A., Gottfried, J., & Green, S. A. (2020). Analysis of Open Data and Computational Reproducibility in Registered Reports in Psychology. Advances in Methods and Practices in Psychological Science, 3(2), 229–237. https://doi.org/10.1177/2515245920918872"
  },
  {
    "objectID": "reasons_research2.html#reuse",
    "href": "reasons_research2.html#reuse",
    "title": "5  Research II",
    "section": "5.1 Reuse",
    "text": "5.1 Reuse\n\n\nThe reuse of research data can take many forms\n\n\n\n\n\n\n\n\n\n\nPurpose\nAdvantage\nNeeds\n\n\n\n\nAnswer new research questions\nSaves resources\nanalysis potential of data, good documentation (Logan et al., 2021; Steinhardt et al., 2021)\n\n\nTeaching / student theses\nReal-life-oriented education\ngood documentation\n\n\nMeta-analyses\nEasier estimation of parameters\nStrictly reproducible code (e.g., Burgard et al., 2022)\n\n\nHistorical perspective\nData as historical artifacts\nPotential of data varies\n\n\n\n\n\n\n\nQuestions to be answered at the end?\nPlease put them here!\n\n\nBurgard, T., Bosnjak, M., & Studtrucker, R. (2022). PsychOpen CAMA: Publication of community-augmented meta-analyses in psychology. Research Synthesis Methods, 13(1), 134–143. https://doi.org/10.1002/jrsm.1536\n\n\nLogan, J. A. R., Hart, S. A., & Schatschneider, C. (2021). Data Sharing in Education Science. AERA Open, 7, 233285842110064. https://doi.org/10.1177/23328584211006475\n\n\nSteinhardt, I., Fischer, C., Heimstädt, M., Hirsbrunner, S. D., İkiz-Akıncı, D., Kressin, L., Kretzer, S., Möllenkamp, A., Porzelt, M., Rahal, R.-M., Schimmler, S., Wilke, R., & Wünsche, H. (2021). Opening up and Sharing Data from Qualitative Research: A Primer: Results of a workshop run by the research group ,,Digitalization and Science“ at the Weizenbaum Institute in Berlin on January 17, 2020. https://doi.org/10.34669/WI.WS/17"
  },
  {
    "objectID": "reasons_researcher1.html#researchers-perceptions",
    "href": "reasons_researcher1.html#researchers-perceptions",
    "title": "6  Researcher",
    "section": "6.1 Researchers’ perceptions",
    "text": "6.1 Researchers’ perceptions\nOpen Data Survey (Goodey et al., 2022)\n\n75% of researchers say there is too little credit for sharing data\nmain drivers:\n\nperceived higher citation (67%)\nincreased perceived impact and visibility (61%)"
  },
  {
    "objectID": "reasons_researcher1.html#classical-metrics",
    "href": "reasons_researcher1.html#classical-metrics",
    "title": "6  Researcher",
    "section": "6.2 Classical metrics",
    "text": "6.2 Classical metrics\n\nData for reuse: Additional publication (e.g., data note in F1000 Research)\nIs there higher citation?\n\nstudies with available data: 9% more citations (Piwowar & Vision, 2013)\nstudies with link to data in a repository: 25% higher citation rates (Colavizza.etal.2020?)\n\n\nBut:\nSelection bias: Willingness to share  strength of evidence and quality of reporting (Wicherts.etal.2011?)\nBut:\nWith higher transparency, researchers have higher trust in authors (Schneider et al., 2022)"
  },
  {
    "objectID": "reasons_researcher1.html#new-metrics-get-hired",
    "href": "reasons_researcher1.html#new-metrics-get-hired",
    "title": "6  Researcher",
    "section": "6.3 New metrics: Get hired!",
    "text": "6.3 New metrics: Get hired!\nnew metrics for evaluation evolving\n\nCoARA: “Value outputs associated with openness (FAIR data sets, […]” (CoARA, 2022, p. 21)\n\nsignatories: DGPs, ERC, European Commission, DFG, Leibniz Association, …\n\nExample: DGPs recommendations on hiring and promotion (Gärtner et al., 2022; Schönbrodt et al., 2022)\n\n\n(Schönbrodt et al., 2022, p. 4)\n\n\nQuestions to be answered at the end?\nPlease put them here!\n\n\n\n\n\n\nCoARA. (2022). Agreement on Reforming Research Assessment.\n\n\nGärtner, A., Leising, D., & Schönbrodt, F. D. (2022). Responsible Research Assessment II: A specific proposal for hiring and promotion in psychology. PsyArXiv. https://doi.org/10.31234/osf.io/5yexm\n\n\nGoodey, G., Hahnel, M., Zhou, Y., Jiang, L., Chandramouliswaran, I., Hafez, A., Paine, T., Gregurick, S., Simango, S., Peña, J. M. P., Murray, H., Cannon, M., Grant, R., McKellar, K., & Day, L. (2022). The State of Open Data 2022. https://doi.org/10.6084/m9.figshare.21276984.v5\n\n\nPiwowar, H. A., & Vision, T. J. (2013). Data reuse and the open data citation advantage. PeerJ, 1, e175. https://doi.org/10.7717/peerj.175\n\n\nSchneider, J., Rosman, T., Kelava, A., & Merk, S. (2022). Do Open-Science Badges Increase Trust in Scientists Among Undergraduates, Scientists, and the Public? Psychological Science, 33(9), 1588–1604. https://doi.org/10.1177/09567976221097499\n\n\nSchönbrodt, F., Gärtner, A., Frank, M., Gollwitzer, M., Ihle, M., Mischkowski, D., Phan, L. V., Schmitt, M., Scheel, A. M., Schubert, A.-L., Steinberg, U., & Leising, D. (2022). Responsible Research Assessment I: Implementing DORA for hiring and promotion in psychology. https://doi.org/10.23668/PSYCHARCHIVES.8162"
  },
  {
    "objectID": "definitions1.html",
    "href": "definitions1.html",
    "title": "7  Openness",
    "section": "",
    "text": "Definition:\n\nanyone\ncan readily access the data\nat no more than a reasonable reproduction cost (i.e., internet connection)\n\n(Open Knowledge Foundation, 2023)\n\n\n\n\n\n\n\n\nOpenness is not a dogma and not a dichotomy\n\n\n\n“As open as possible as closed as necessary”\n(European Commission, 2023, p. 36)\n\n\n\n\n\n\nQuestions to be answered at the end?\nPlease put them here!\n\n\nEuropean Commission. (2023). Horizon Europe (HORIZON). HE Programme Guide. Version 4.0. Publications Office.\n\n\nOpen Knowledge Foundation. (2023). What is Open Data? In Open Data Handbook. https://opendatahandbook.org/guide/en/what-is-open-data/."
  },
  {
    "objectID": "definitions2.html",
    "href": "definitions2.html",
    "title": "8  FAIRness",
    "section": "",
    "text": "Purpose:\n\n“enhancing the ability of machines to automatically find and use the data, in addition to supporting its reuse by individuals” (Wilkinson et al., 2016, p. 1)\n\nSee also go-fair.org\n\n\n\n\n\n\n\n\nFAIRness vs. openness\n\n\n\n“does not necessarily mean that data has to be “open” […] even highly protected data can be FAIR data”\n(Kraft, 2023)\n\n\n\n\n\nFindableAccessibleInteroperableReusable\n\n\nThe problem:\nJust because we provide data online, doesn’t mean that others will find it.\nWe could have the greatest data set to answer further research questions - if our colleagues don’t know it exists or can’t locate the data, openness will be of little value.\nThe solutions:\n\nGet a persistent identifier (e.g., DOI), where you provided your data\n\nsearch for a research data center that fits your needs: re3data.org\nrecommended research data centers: Verbund FDB (education, Germany), RDC at ZPID (psychology, Germany), …\nrecommended repositories: Zenodo, psycharchives.org, osf.io, …\n\nMention DOI in publication that builds on this data (e.g., in the “data accessibility statement”)\nDescribe your data as richly as possible (metadata). Research data centers offer form fields tailored to the discipline or data type. With repositories use alternative possibilities, such as keyword fields.\n\ne.g., which variables does the quantitative data set contain?\ne.g., which topics does your data cover?\ne.g., which population did you draw your sample from?\n\n\n\n\nThe problem:\nJust because others find our data doesn’t mean the access barriers are as low as possible and doesn’t mean they know in which way they are allowed to access it. Examples:\n\nProviding a link to the data in the text of a paywalled journal article\nUnclear licensing / use conditions when providing data (e.g., are non-researchers allowed to access the data or is it only open for qualified researchers?)\n\nThe solutions:\n\nMake sure access is free of charge (or as cheap as possible)\n\ne.g., by providing link to data in publicly accessible sections of journal articles that are not open access\ne.g., by using repositories or research data centers that allow access free of charge\n\nMake sure users know if they can access and under which conditions\n\ne.g., research data centers ensure that terms of use are clear (who may access under what conditions) and offer different levels of access restriction\ne.g., on repositories provide a readme-file and an open license (e.g., CC0, CC-BY, CC-BY-SA) with data sets for access cases\n\n\n\n\nThe problem:\nJust because others downloaded our data doesn’t mean they can open and manipulate it.\nThe solutions:\n\nUse file formats with open licenses\n\ne.g., tabular data: CSV (with additional labelling script), RData\ne.g., text data: PDF, HTML, ODT, RTF\n\nMake sure users know how different files are related to one another\n\ne.g., define which file contains student data and which teacher data\ne.g., define which file contains data from cohort 1 and which cohort 2, …\n\n\n\n\nThe problem:\nJust because others opened our data doesn’t mean they understand the data and its use-conditions. Examples:\n\nOthers can’t understand what the column names of the tabular data set mean: Which columns in the data set relate to which variables in the journal article?\nCan someone from sociology use the data set from psychology they found on osf.io?\nDoes someone reusing a data set have to cite the authors?\n\nThe solutions:\n\nAdhere to standards in folder organization\n\ne.g., PSYCH-DS (see technical specification draft)\n\nRich description/explanation of what user will find in the data set (≠ meta descriptions about the data set as a whole, as for accessibility)\n\ne.g., provide a codebook. How to semi-automatically create a codebook, see the R package codebook\n\nProvide a license for the use-cases\n\nagain, research data centers ensure that terms of use are clear (who may use under what conditions)\nagain, on repositories provide a readme-file and an open license (e.g., CC0, CC-BY, CC-BY-SA) with data sets for the use-cases\n\n\n\n\n\n\n\n(FAIR principles and the role of scientists: Kraft, 2023)\n\n\n\n\nQuestions to be answered at the end?\nPlease put them here!\n\n\nKraft, A. (2023). The FAIR Data Principles. https://doi.org/10.23668/PSYCHARCHIVES.13577\n\n\nWilkinson, M. D., Dumontier, M., Aalbersberg, Ij. J., Appleton, G., Axton, M., Baak, A., Blomberg, N., Boiten, J.-W., da Silva Santos, L. B., Bourne, P. E., Bouwman, J., Brookes, A. J., Clark, T., Crosas, M., Dillo, I., Dumon, O., Edmunds, S., Evelo, C. T., Finkers, R., … Mons, B. (2016). The FAIR Guiding Principles for scientific data management and stewardship. Scientific Data, 3(1), 160018. https://doi.org/10.1038/sdata.2016.18"
  },
  {
    "objectID": "definitions_exercise.html",
    "href": "definitions_exercise.html",
    "title": "9  Exercise",
    "section": "",
    "text": "Go to this repository\nDiscuss for which purposes you consider this type of sharing to be suitable / less suitable\nDiscuss what you think makes this type of data sharing FAIR and what could be improved\n\n\n\n\n\n\nQuestions to be answered at the end?\nPlease put them here!"
  },
  {
    "objectID": "limits1.html#not-being-open-may-be-important",
    "href": "limits1.html#not-being-open-may-be-important",
    "title": "10  Limits",
    "section": "10.1 Not being open may be important",
    "text": "10.1 Not being open may be important\nWhen does “as closed as necessary” apply?\nThe protection of individuals comes first and is more important than the potential reuse of data\n\nMarginalized/vulnerable groups“Closed doors”Costs &gt; benefit\n\n\n\ne.g., individuals traumatized by war or who experienced sexual abuse\nAt the same time: Can sharing data help to protect these groups from being over-researched (possibly re-traumatization)?\n\n\n\n\ncases in which field access is obstructed or denied by the data provision (Prosser et al., 2022)\ncases in which sharing reduces the reduces the willingness to participate\n\n\n\n\ne.g., low reuse potential -&gt; publish for reproducibility\ne.g., when obtaining permission from the school authorities is extremely complicated\ne.g., epistemic problem: context of data collection is highly relevant and other researchers “haven’t been there” (Mauthner et al., 1998) -&gt; publish for intersubjective comprehensibility\ne.g., can’t anonymize data -&gt; synthpop, create input-output-documents via RMarkdown/Quarto"
  },
  {
    "objectID": "limits1.html#its-not-all-your-responsibility",
    "href": "limits1.html#its-not-all-your-responsibility",
    "title": "10  Limits",
    "section": "10.2 It’s not all your responsibility",
    "text": "10.2 It’s not all your responsibility\n\nResponsibility of opening research is a collective responsibility in the “research ecosystem” (European Commission, 2018; RfII, 2019)\nResearchers are just one part of this\n\n\n\n\n\n\n\n\nInfrastructure\n\n\n\n\n\n\nDoes suitable infrastructure exist?\nIs it “easy to use” and cheap?\nIs it tailored to my needs and type of data?\nDoes it allow the implementation of FAIR data?\nAre there resources to support data sharing?\n\n\n\n\n\n\n\n\n\n\nContext\n\n\n\n\n\n\nDo scientific societies, journals, or research funders encourage sharing?\nIs it common practice (“culture”) in my field of research to share data? (Bishop, 2006)\nAre there standards established for data sharing?\nDo ethics committees request detailed reasoning for the intent to collect own data as opposed to re-using?\n\n\n\n\n\n\n\n\n\n\nResearch project\n\n\n\n\n\nSee reasons above on\n\nMarginalized/vulnerable groups\n“Closed doors”\nCosts &gt; benefit\n\n\n\n\n\n\n\n\n\n\nResearchers\n\n\n\n\n\n\nWillingness and concerns toward sharing data (Mozersky et al., 2021)\nKnowledge, experiences and skills with relevant processes\n\n\n\n\n\n\nQuestions to be answered at the end?\nPlease put them here!\n\n\n\n\n\n\nBishop, L. (2006). A Proposal for Archiving Context for Secondary Analysis. Methodological Innovation Online, 1(2), 10–20. https://doi.org/10.4256/mio.2006.0008\n\n\nEuropean Commission. (2018). OSPP-REC: Open Science Policy Platform Recommendations. Publications Office.\n\n\nMauthner, N. S., Parry, O., & Backett-Milburn, K. (1998). The Data are Out there, or are They? Implications for Archiving and Revisiting Qualitative Data. Sociology, 32(4), 733–745. https://doi.org/10.1177/0038038598032004006\n\n\nMozersky, J., McIntosh, T., Walsh, H. A., Parsons, M. V., Goodman, M., & DuBois, J. M. (2021). Barriers and facilitators to qualitative data sharing in the United States: A survey of qualitative researchers. PLOS ONE, 16(12), e0261719. https://doi.org/10.1371/journal.pone.0261719\n\n\nProsser, A. M. B., Hamshaw, R. J. T., Meyer, J., Bagnall, R., Blackwood, L., Huysamen, M., Jordan, A., Vasileiou, K., & Walter, Z. (2022). When open data closes the door: A critical examination of the past, present and the potential future for open data guidelines in journals. British Journal of Social Psychology, 12576. https://doi.org/10.1111/bjso.12576\n\n\nRfII. (2019). Herausforderung Datenqualität Empfehlungen zur Zukunftsfähigkeit von Forschung im digitalen Wandel."
  },
  {
    "objectID": "workflow1.html",
    "href": "workflow1.html",
    "title": "11  Overview",
    "section": "",
    "text": "Table: Steps & resources\n\n\n\n\n\n\n\n\nWhat\nResources\n\n\n\n\nSearch for reusable data\nResearch data centers have searchable databases re3data.org, Verbund FDB, RDC at ZPID\n\n\nSharing for reuse or reproducibility\nCosts: How much effort is required? Consent for reuse available?Benefits: Analysis potential, Quality of data\n\n\nData management plan\nTemplates/ToolsStamp (VerbundFDB)DMP template (ERC)Online tool (Open Aire)Online tool “DataWiz” (ZPID)StandardD-Psy-FAIR (ZPID)\n\n\nDecide for a repository or RDC\nResearch data center:Search: re3data.orgVerbund FDB (education, Germany)RDC at ZPID (psychology, Germany)RepositoriesZenodopsycharchives.orgosf.io\n\n\nInformed consent\nChecklist, GermanTemplate, German standard languageTemplate, German plain languageTemplate (qualitative data), GermanExplanations + template (DGPs), GermanOverview + links (ZPID), EnglishExplanations + definitions (Michigan Tech), US\n\n\nAccess restrictions\nExamples (VerbundFDB)Examples (DGPs)There are alternatives to restricting access!\n\n\nCreate codebook\nR Package codebookcodebook from DataWiz\n\n\n\n\n\n\n\n\n\n\n\nQuestions to be answered at the end?\nPlease put them here!"
  },
  {
    "objectID": "workflow2.html#search-for-reusable-data",
    "href": "workflow2.html#search-for-reusable-data",
    "title": "12  Workflow 1",
    "section": "12.1 Search for reusable data",
    "text": "12.1 Search for reusable data\nWhy?\nFor resource intensive data collections this could save you a lot of time and money\nResources\nResearch data centers have searchable databases\n\nre3data.org (Database to search for databases)\nVerbund FDB (Education)\nRDC at ZPID (Psychology)"
  },
  {
    "objectID": "workflow2.html#decide-between-sharing-for-reuse-or-reproducibility",
    "href": "workflow2.html#decide-between-sharing-for-reuse-or-reproducibility",
    "title": "12  Workflow 1",
    "section": "12.2 Decide between sharing for reuse or reproducibility",
    "text": "12.2 Decide between sharing for reuse or reproducibility\nWhy?\n\nProviding data at a reseach data center costs time and money for you and the data center\nTypically,\n\nsharing for reuse purposes is suited for research data centers\nsharing for reproducibility purposes is suited for repositories\n\n\nResources\nI am not aware of any standards to make this decision. Here are a couple of guidelines to decide, if your data is fit for reuse\n\nCosts:\n\nHow much effort is required for well-documented data sharing (e.g., Does a codebook exist? What steps are necessary for data cleaning/editing?)\nIs there consent for reuse available or would it have to be obtained retrospectively?\n\nBenefits:\n\nAnalysis potential (e.g., not fully analyzed, type of data, connected with other data sources)\nQuality of data (e.g., representative, size, special features of sample)\n\n\n\n\nQuestions to be answered at the end?\nPlease put them here!"
  },
  {
    "objectID": "workflow3.html#write-a-data-management-plan",
    "href": "workflow3.html#write-a-data-management-plan",
    "title": "13  Workflow 2",
    "section": "13.1 Write a data management plan",
    "text": "13.1 Write a data management plan\nWhy?\n\nsupports researchers in the process of generating FAIR research data\nensures good scientific practice\n\nResources\nTemplates and online tools for specific applications\n\nTemplate Standardized data management plan for educational research “Stamp” (FDZ Bildung): Detailed form with specific instructions and assistance\nFor rapid documentation: DMP template (European Research Council) with four open questions\nOnline tool for machine-readable DMPs (Open Aire)\nOnline tool supporting the creation of a DMP (ZPID)\n\nStandards\n\nD-Psy-FAIR (Blask et al., 2022)\n\nManual\nOnline Tutorial\nSlides"
  },
  {
    "objectID": "workflow3.html#decide-for-a-repository-or-research-data-center",
    "href": "workflow3.html#decide-for-a-repository-or-research-data-center",
    "title": "13  Workflow 2",
    "section": "13.2 Decide for a repository (or research data center)",
    "text": "13.2 Decide for a repository (or research data center)\nWhy?\nDeciding on a specific repository or research data center early on helps to\n\nmeet its requirements\nidentify whether there are templates available\nidentify whether the employees can support the sharing process (in the case or RDC)\n\nResources\n\nsearch for a research data center that fits your needs: re3data.org\nrecommended research data centers: Verbund FDB (education, Germany), RDC at ZPID (psychology, Germany), …\nrecommended repositories: Zenodo, psycharchives.org, osf.io, …\n\n\n\nQuestions to be answered at the end?\nPlease put them here!\n\n\n\n\n\n\nBlask, K., Latz, M., Müller, M.-L., & Gellert, S. (2022). D-Psy-FAIR: Four simple steps to sustainable data documentation in psychology. PsychArchives. https://doi.org/10.23668/PSYCHARCHIVES.12180"
  },
  {
    "objectID": "workflow4.html#informed-consent",
    "href": "workflow4.html#informed-consent",
    "title": "14  Workflow 3",
    "section": "14.1 Informed consent",
    "text": "14.1 Informed consent\nWhy?\n\nPersonal data is subject to General Data Protection Regulation (GDPR)\nInformed consent must therefore fulfill a number of requirements. E.g.,\n\npurpose of data collection (includes sharing the data and future use) therefore often “broad consent”\nparticipation is voluntary and without disadvantages\nrevocation is possible at any time (until anonymized)\n\n\nResources\n\nChecklist of legally compliant consent forms, German (VerbundFDB, 2019)\nTemplate for informed consent, German standard language (VerbundFDB, 2018)\nTemplate for informed consent, German plain language (VerbundFDB, 2018)\nTemplate for informed consent, German (Qualiservice)\nExplanations including template (DGPs), German (not specific for reuse)\nOverview and links concerning informed consent (ZPID), English\nExplanations and definitions around informed consent (Michigan Tech), US (not specific for reuse)"
  },
  {
    "objectID": "workflow4.html#decide-for-access-restrictions",
    "href": "workflow4.html#decide-for-access-restrictions",
    "title": "14  Workflow 3",
    "section": "14.2 Decide for access restrictions",
    "text": "14.2 Decide for access restrictions\nWhy?\n\nSome data cannot or should not be anonymized (e.g., losing their reuse potential)\n\nTherefore access needs to be restricted to certain groups (as defined in consent form)\n\nSome researchers fear being scooped (Laine.2017?)\n\n\n\n\n\n\n\nWith repositories…\n\n\n\n\n\nrestriction levels are usually limited to\n\npublic (everybody sees everything)\nprivate (only you and your collaborators see everything)\n\n\n\n\n\n\n\n\n\n\nWith research data centers…\n\n\n\n\n\nthere are different restriction levels possible for different files (in the same project). Restriction levels depend on what the research data center offers.\n\n\n\n\n\n\n\n\n\n\n\nLevel\nPrerequesite\nFor what\n\n\n\n\n\nPublic Usefile\n\nanonymized data, codebooks, transcription rules\n\n\n\nStudent Usefile\nShort application states use purpose\nnon-anonymized data with right to use for teaching\n\n\n\nScientific Usefile\nLonger application states use purpose, handling of data, and data analyses; identification via PostIdent\nnon-anonymized data with right to use for research\n\n\n\nRemote Access\n… + access only via virtual machine\nnon-anonymized sensible data with right to use for research\n\n\n\nSafe room\n… + access only in person at research institute\nnon-anonymized very sensible data with right to use for research\n\n\n\n\n\n\nAn example: Project DESI, where\n\ncodebooks are publicly accessible (files on the right side)\nvideo data are restricted for scientific use (files on the bottom of page)\n\n\n\n\nResources\n\nExamples of restriction levels (VerbundFDB) (Meyermann & Porzelt, 2019, p. 30f)\nExamples of restriction levels (DGPs) (DGPs, 2021, p. 141ff)\n\nAlternatives\n\nEmbargo period\n\nSpecify a time period, before data go public\nPossible with research data centers and some repositories\n\nExclude certain research questions from reuse\n\nSpecify these research questions in the terms of use\nUsually only possible with research data centers, except you are writing a very good license yourself\n\nCreate synthetic data (e.g., with R package synthpop)\n\nMimics the properties of your data\nThen possible to share this synthetic data set\n\n\n\n\nQuestions to be answered at the end?\nPlease put them here!\n\n\n\n\n\n\nDGPs. (2021). Management und Bereitstellung von Forschungsdaten in der Psychologie: Überarbeitung der DGPs-Empfehlungen: DGPs-Kommission ,,Open Science“ (beschlossen durch den Vorstand der DGPs am 26. 06. 2020). Psychologische Rundschau, 72(2), 132–146. https://doi.org/10.1026/0033-3042/a000514\n\n\nMeyermann, A., & Porzelt, M. (2019). Datenschutzrechtliche Anforderungen in der empirischen Bildungsforschung. Eine Handreichung. Version 2.1. https://doi.org/10.25656/01:21990"
  },
  {
    "objectID": "workflow5.html#create-codebook",
    "href": "workflow5.html#create-codebook",
    "title": "15  Workflow 4",
    "section": "15.1 Create codebook",
    "text": "15.1 Create codebook\nWhy?\nRemember?\n\nVagueness Makes Assessing Reproducibility a Nightmare\nmost successful reproductions are predominantly the result of tedious and time-consuming work information about the provided raw data was often difficult to understand, and information about the relevant variables, data manipulations, and the used statistical model was often vague or inaccurate (Artner et al., 2021, p. 12)\n\nResources\n\nR Package codebook\n\nsemi-automated creation of a codebook (depending on how well prepared/labelled your data set is)\nin combination with the formr survey framework, this package saves you a ton of time\nstill has some minor bugs, be prepared to mingle with it\n\nCodebook as a result of using DataWiz\n\n\n\nQuestions to be answered at the end?\nPlease put them here!\n\n\n\n\n\n\nArtner, R., Verliefde, T., Steegen, S., Gomes, S., Traets, F., Tuerlinckx, F., & Vanpaemel, W. (2021). The reproducibility of statistical results in psychological research: An investigation using unpublished raw data. Psychological Methods, 26(5), 527–546. https://doi.org/10.1037/met0000365"
  },
  {
    "objectID": "barriers1.html",
    "href": "barriers1.html",
    "title": "16  Exercise: Barriers",
    "section": "",
    "text": "Let’s assume: Sharing data is possible. In one way or the other.\n\nWhy isn’t everybody sharing all data “as open as possible as closed as necessary”?\n\n\nCheck out the flow chart again (see below)\nIndividually [3min]: Reflect on\n\nWhat is a barrier/challenge to you?\nWhat might be a powerful barrier/challenge for others?\n\nIn the breakout rooms [12min]: Discuss\n\nWhat are the biggest barriers for you/others?\nWhat would be different in an “ideal world” that would lead to you/others overcoming these barriers?\nDocument the barriers & your needs in this sheet\n\n\n\n\nQuestions to be answered at the end?\nPlease put them here!"
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "References",
    "section": "",
    "text": "Artner, R., Verliefde, T., Steegen, S., Gomes, S., Traets, F.,\nTuerlinckx, F., & Vanpaemel, W. (2021). The reproducibility of\nstatistical results in psychological research: An\ninvestigation using unpublished raw data. Psychological\nMethods, 26(5), 527–546. https://doi.org/10.1037/met0000365\n\n\nBishop, L. (2006). A Proposal for Archiving\nContext for Secondary Analysis. Methodological\nInnovation Online, 1(2), 10–20. https://doi.org/10.4256/mio.2006.0008\n\n\nBlask, K., Latz, M., Müller, M.-L., & Gellert, S. (2022).\nD-Psy-FAIR: Four simple steps to\nsustainable data documentation in psychology.\nPsychArchives. https://doi.org/10.23668/PSYCHARCHIVES.12180\n\n\nBurgard, T., Bosnjak, M., & Studtrucker, R. (2022). PsychOpen\nCAMA: Publication of community-augmented\nmeta-analyses in psychology. Research Synthesis Methods,\n13(1), 134–143. https://doi.org/10.1002/jrsm.1536\n\n\nClyburne-Sherin, A., Fei, X., & Green, S. A. (2019). Computational\nReproducibility via Containers in\nPsychology. Meta-Psychology, 3. https://doi.org/10.15626/MP.2018.892\n\n\nCoARA. (2022). Agreement on Reforming Research\nAssessment.\n\n\nDFG. (2015). DFG Guidelines on the\nHandling of Research Data.\n\n\nDFG. (2019). Guidelines for Safeguarding Good Research\nPractice. Code of Conduct.\n\n\nDGfE, GEBF, & GFD. (2020). Gemeinsame Stellungnahme\nder Deutschen Gesellschaft für\nErziehungswissenschaft (DGfE), der\nGesellschaft für Empirische Bildungsforschung\n(GEBF) und der Gesellschaft für\nFachdidaktik (GFD) zur\nArchivierung, Bereitstellung und\nNachnutzung von Forschungsdaten in den\nErziehungs- und Bildungswissenschaften und\nFachdidaktiken.\n\n\nDGPs. (2021). Management und Bereitstellung von Forschungsdaten in\nder Psychologie: Überarbeitung der DGPs-Empfehlungen: DGPs-Kommission\n,,Open Science“ (beschlossen durch den Vorstand der DGPs am 26. 06.\n2020). Psychologische Rundschau, 72(2),\n132–146. https://doi.org/10.1026/0033-3042/a000514\n\n\nDGS. (2019). Stellungnahme: Bereitstellung und\nNachnutzung von Forschungsdaten in der\nSoziologie.\n\n\nERC. (2022). Open Research Data and Data\nManagement Plans. Information for ERC\ngrantees.\n\n\nErrington, T. M., Denis, A., Perfito, N., Iorns, E., & Nosek, B. A.\n(2021). Challenges for assessing replicability in preclinical cancer\nbiology. eLife, 10, e67995. https://doi.org/10.7554/eLife.67995\n\n\nEuropean Commission. (2018). OSPP-REC: Open\nScience Policy Platform Recommendations. Publications\nOffice.\n\n\nEuropean Commission. (2023). Horizon Europe\n(HORIZON). HE Programme Guide.\nVersion 4.0. Publications Office.\n\n\nGabelica, M., Bojčić, R., & Puljak, L. (2022). Many researchers were\nnot compliant with their published data sharing statement: A\nmixed-methods study. Journal of Clinical Epidemiology,\n150, 33–41. https://doi.org/10.1016/j.jclinepi.2022.05.019\n\n\nGärtner, A., Leising, D., & Schönbrodt, F. D. (2022).\nResponsible Research Assessment II: A\nspecific proposal for hiring and promotion in psychology.\nPsyArXiv. https://doi.org/10.31234/osf.io/5yexm\n\n\nGollwitzer, M., Abele-Brehm, A., Fiebach, C. J., Ramthun, R., Scheel,\nA., Schönbrodt, F., & Steinberg, U. (2021). Management und\nBereitstellung von Forschungsdaten in der Psychologie: Überarbeitung der\nDGPs-Empfehlungen: DGPs-Kommission ,,Open Science“ (beschlossen durch\nden Vorstand der DGPs am 26. 06. 2020). Psychologische\nRundschau, 72(2), 132–146. https://doi.org/10.1026/0033-3042/a000514\n\n\nGoodey, G., Hahnel, M., Zhou, Y., Jiang, L., Chandramouliswaran, I.,\nHafez, A., Paine, T., Gregurick, S., Simango, S., Peña, J. M. P.,\nMurray, H., Cannon, M., Grant, R., McKellar, K., & Day, L. (2022).\nThe State of Open Data 2022. https://doi.org/10.6084/m9.figshare.21276984.v5\n\n\nKitzes, J., Turek, D., & Deniz, F. (Eds.). (2018). The practice\nof reproducible research: Case studies and lessons from the\ndata-intensive sciences. University of California\nPress.\n\n\nKraft, A. (2023). The FAIR Data Principles. https://doi.org/10.23668/PSYCHARCHIVES.13577\n\n\nLogan, J. A. R., Hart, S. A., & Schatschneider, C. (2021). Data\nSharing in Education Science. AERA\nOpen, 7, 233285842110064. https://doi.org/10.1177/23328584211006475\n\n\nMauthner, N. S., Parry, O., & Backett-Milburn, K. (1998). The\nData are Out there, or are They?\nImplications for Archiving and\nRevisiting Qualitative Data. Sociology,\n32(4), 733–745. https://doi.org/10.1177/0038038598032004006\n\n\nMeyermann, A., & Porzelt, M. (2019). Datenschutzrechtliche\nAnforderungen in der empirischen Bildungsforschung. Eine Handreichung.\nVersion 2.1. https://doi.org/10.25656/01:21990\n\n\nMozersky, J., McIntosh, T., Walsh, H. A., Parsons, M. V., Goodman, M.,\n& DuBois, J. M. (2021). Barriers and facilitators to qualitative\ndata sharing in the United States: A survey of\nqualitative researchers. PLOS ONE, 16(12), e0261719.\nhttps://doi.org/10.1371/journal.pone.0261719\n\n\nObels, P., Lakens, D., Coles, N. A., Gottfried, J., & Green, S. A.\n(2020). Analysis of Open Data and Computational\nReproducibility in Registered Reports in\nPsychology. Advances in Methods and Practices in\nPsychological Science, 3(2), 229–237. https://doi.org/10.1177/2515245920918872\n\n\nOpen Knowledge Foundation. (2023). What is Open Data? In\nOpen Data Handbook.\nhttps://opendatahandbook.org/guide/en/what-is-open-data/.\n\n\nPiwowar, H. A., & Vision, T. J. (2013). Data reuse and the open data\ncitation advantage. PeerJ, 1, e175. https://doi.org/10.7717/peerj.175\n\n\nProsser, A. M. B., Hamshaw, R. J. T., Meyer, J., Bagnall, R., Blackwood,\nL., Huysamen, M., Jordan, A., Vasileiou, K., & Walter, Z. (2022).\nWhen open data closes the door: A critical examination of\nthe past, present and the potential future for open data guidelines in\njournals. British Journal of Social Psychology, 12576. https://doi.org/10.1111/bjso.12576\n\n\nRfII. (2019). Herausforderung Datenqualität\nEmpfehlungen zur Zukunftsfähigkeit von\nForschung im digitalen Wandel.\n\n\nSchneider, J., Rosman, T., Kelava, A., & Merk, S. (2022). Do\nOpen-Science Badges Increase Trust in Scientists\nAmong Undergraduates, Scientists, and the\nPublic? Psychological Science, 33(9),\n1588–1604. https://doi.org/10.1177/09567976221097499\n\n\nSchönbrodt, F., Gärtner, A., Frank, M., Gollwitzer, M., Ihle, M.,\nMischkowski, D., Phan, L. V., Schmitt, M., Scheel, A. M., Schubert,\nA.-L., Steinberg, U., & Leising, D. (2022). Responsible\nResearch Assessment I: Implementing DORA for\nhiring and promotion in psychology. https://doi.org/10.23668/PSYCHARCHIVES.8162\n\n\nSteinhardt, I., Fischer, C., Heimstädt, M., Hirsbrunner, S. D.,\nİkiz-Akıncı, D., Kressin, L., Kretzer, S., Möllenkamp, A., Porzelt, M.,\nRahal, R.-M., Schimmler, S., Wilke, R., & Wünsche, H. (2021).\nOpening up and Sharing Data from Qualitative\nResearch: A Primer: Results of a\nworkshop run by the research group ,,Digitalization and\nScience“ at the Weizenbaum Institute in\nBerlin on January 17, 2020. https://doi.org/10.34669/WI.WS/17\n\n\nWilkinson, M. D., Dumontier, M., Aalbersberg, Ij. J., Appleton, G.,\nAxton, M., Baak, A., Blomberg, N., Boiten, J.-W., da Silva Santos, L.\nB., Bourne, P. E., Bouwman, J., Brookes, A. J., Clark, T., Crosas, M.,\nDillo, I., Dumon, O., Edmunds, S., Evelo, C. T., Finkers, R., … Mons, B.\n(2016). The FAIR Guiding Principles for scientific data\nmanagement and stewardship. Scientific Data, 3(1),\n160018. https://doi.org/10.1038/sdata.2016.18"
  }
]